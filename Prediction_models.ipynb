{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf56b5c2-0d4d-45f8-88ad-4171fabc40e6",
   "metadata": {},
   "source": [
    "# Machine Learning Model Application\r\n",
    "\r\n",
    "In this part, after merging the `GENERAL_STATS` dataset and `EMA_data` dataset, we will clean the data to create a dataset characterized by all the features and the target variable.\r\n",
    "\r\n",
    "## Features Used for Training the Machine Learning Models:\r\n",
    "\r\n",
    "- **B365H**: Betting odds for a home win (Bet365).\r\n",
    "- **B365D**: Betting odds for a draw (Bet365).\r\n",
    "- **B365A**: Betting odds for an away win (Bet365).\r\n",
    "- **HTGD**: Goal difference for the home team up to the match.\r\n",
    "- **ATGD**: Goal difference for the away team up to the match.\r\n",
    "- **DiffPts**: Difference in total points between the two teams.\r\n",
    "- **DiffFormPts**: Difference in recent form points between the two teams.\r\n",
    "- **f_cornersAgainstHome**: Corners conceded by the home team (EMA feature).\r\n",
    "- **f_cornersForHome**: Corners earned by the home team (EMA feature).\r\n",
    "- **f_freesAgainstHome**: Fouls conceded by the home team (EMA feature).\r\n",
    "- **f_freesForHome**: Fouls earned by the home team (EMA feature).\r\n",
    "- **f_goalsAgainstHome**: Goals conceded by the home team (EMA feature).\r\n",
    "- **f_goalsForHome**: Goals scored by the home team (EMA feature).\r\n",
    "- **f_halfTimeGoalsAgainstHome**: Half-time goals conceded by the home team (EMA feature).\r\n",
    "- **f_halfTimeGoalsForHome**: Half-time goals scored by the home team (EMA feature).\r\n",
    "- **f_redsAgainstHome**: Red cards received by opponents of the home team (EMA feature).\r\n",
    "- **f_redsForHome**: Red cards received by the home team (EMA feature).\r\n",
    "- **f_shotsAgainstHome**: Shots taken by opponents of the home team (EMA feature).\r\n",
    "- **f_shotsForHome**: Shots taken by the home team (EMA feature).\r\n",
    "- **f_shotsOnTargetAgainstHome**: Shots on target by opponents of the home team (EMA feature).\r\n",
    "- **f_shotsOnTargetForHome**: Shots on target by the home team (EMA feature).\r\n",
    "- **f_yellowsAgainstHome**: Yellow cards received by opponents of the home team (EMA feature).\r\n",
    "- **f_yellowsForHome**: Yellow cards received by the home team (EMA feature).\r\n",
    "- **f_cornersAgainstAway**: Corners conceded by the away team (EMA feature).\r\n",
    "- **f_cornersForAway**: Corners earned by the away team (EMA feature).\r\n",
    "- **f_freesAgainstAway**: Fouls conceded by the away team (EMA feature).\r\n",
    "- **f_freesForAway**: Fouls earned by the away team (EMA feature).\r\n",
    "- **f_goalsAgainstAway**: Goals conceded by the away team (EMA feature).\r\n",
    "- **f_goalsForAway**: Goals scored by the away team (EMA feature).\r\n",
    "- **f_halfTimeGoalsAgainstAway**: Half-time goals conceded by the away team (EMA feature).\r\n",
    "- **f_halfTimeGoalsForAway**: Half-time goals scored by the away team (EMA feature).\r\n",
    "- **f_redsAgainstAway**: Red cards received by opponents of the away team (EMA feature).\r\n",
    "- **f_redsForAway**: Red cards received by the away team (EMA feature).\r\n",
    "- **f_shotsAgainstAway**: Shots taken by opponents of the away team (EMA feature).\r\n",
    "- **f_shotsForAway**: Shots taken by the away team (EMA feature).\r\n",
    "- **f_shotsOnTargetAgainstAway**: Shots on target by opponents of the away team (EMA feature).\r\n",
    "- **f_shotsOnTargetForAway**: Shots on target by the away team (EMA feature).\r\n",
    "- **f_yellowsAgainstAway**: Yellow cards received by opponents of the away team (EMA feature).\r\n",
    "- **f_yellowsForAway**: Yellow cards received by the away team (EMA feature).\r\n",
    "\r\n",
    "## Target Variable:\r\n",
    "\r\n",
    "- **FTR**: \r\n",
    "  - `H`: Home Win  \r\n",
    "  - `D`: Draw  \r\n",
    "  - `A`: Away Win\r\n",
    "lowsForAway'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734484d1-55e7-4c80-bd8d-e79172a60532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from MachineLearningModels import*\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DATA_PATH='data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d0caef-a212-4699-829e-3bf520c9e328",
   "metadata": {},
   "source": [
    "First of all we use discard the variables in the datasets we are sure we are not going to use in the analysis. Then we merge the datasets and filter them in order to use only the features to use in our machine learning models.\n",
    "\n",
    "From the GENERAL_STATS dataset one we eliminate:\n",
    "- 'FTHG', 'FTAG': goals in the match, we should predict the result so we don't know it\n",
    "- 'HTGS', 'ATGS', 'HTGC','ATGC': goals done and conceded so far, already considered with the feature HTGD e ATGD\n",
    " - 'HTFormPts','ATFormPts': points home team and away tema in the last 5 mathces. Already considered DiffFormPts\n",
    " - 'HTP', 'ATP':points so far for home and away team so far. Already considered with DiffPts\n",
    " - 'MW', 'HTFormPtsStr', 'ATFormPtsStr'. Useless variables\n",
    "\n",
    "Form the EMA_data dataset we discard: 'Unnamed: 0', 'f_DateHome', 'f_SeasonHome', 'HomeTeam', 'homeGame_x', 'f_DateAway', 'f_SeasonAway','AwayTeam', 'homeGame_y', 'gameId_y','gameId_x' which are either repetition of a variable in GENERAL_STATS or a useless variable\n",
    "\n",
    "Then we merge both variable in order to have a unique dataset which contain all the features that will be used to predict the outcome of each match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13051c8b-6216-4565-9631-f696b57c1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_stats = pd.read_csv('data/GENERAL_STATS.csv')\n",
    "\n",
    "general_stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878e3c1c-4e22-49cf-9e50-631bf4ffc04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_stats.drop(['FTHG', 'FTAG',\n",
    "                 'HTGS','ATGS', 'HTGC', 'ATGC',  'HTFormPts', \n",
    "                 'ATFormPts', 'MW', 'HTFormPtsStr', 'ATFormPtsStr', 'HTP', 'ATP'], axis =1, inplace=True)\n",
    "general_stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d01e864-dd91-42c0-ba48-a68eb4550982",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_dataset = pd.read_csv(\"data/EMA_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f469391-8d8b-4bad-afc0-3722e97d2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_dataset.drop(['Unnamed: 0', 'f_DateHome', 'f_SeasonHome', 'HomeTeam',\n",
    "               'homeGame_x', 'f_DateAway', 'f_SeasonAway', \n",
    "               'AwayTeam', 'homeGame_y'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdbe013-6c50-40e6-b86c-8d00d89c74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset merging w.r.t gameId\n",
    "df = pd.merge(general_stats, ema_dataset, left_on='gameId', right_index=True) \n",
    "df.drop(['gameId_y','gameId_x'], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7dd4c-07bd-4863-b105-a373e6782c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c8968a-8d0c-4a86-b7c5-9f3486893f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(DATA_PATH, 'ML_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6af3f2f-d756-40fd-a499-578e28eb0b66",
   "metadata": {},
   "source": [
    "We save this dataset. We will use it later in order to analyze a feasible Betting strategy (Betting_Strategy.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c0f675-9bb7-4d88-91a9-a5af59d99cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5996f5d8-f2c0-4d4f-bf80-4a131377b45a",
   "metadata": {},
   "source": [
    "## Machine Learning Model Application\n",
    "\n",
    "Now we prepare the dataset to correctly apply the machine learning models.\n",
    "\n",
    "Since these are temporal variables, we cannot use the classic 70/30 or 80/20 random split of the data. Instead, we need to set a cutoff date to divide the data into training and test sets. We decided to use the following split:\n",
    "\n",
    "- **Training data**: From the 16-17 season to the 22-23 season (inclusive - approximately 75% of the data).\n",
    "- **Test data**: The 23-24 season and the 24-25 season (up to the last available match - approximately 25% of the data).\n",
    "\n",
    "Next, all variables are normalized using the `StandardScaler`, and the categories of the target variable (FTR) are transformed as follows:\n",
    "\n",
    "- **FTR**:  \n",
    "  - `H`: Home Win == 2  \n",
    "  - `D`: Draw == 1  \n",
    "  - `A`: Away Win == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c3d3f-1ae5-48fd-b90b-8bef851bbf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data: Include all seasons except 2324 and 2425\n",
    "training_data = df.loc[~(df['Season'] == 2324) & ~(df['Season'] == 2425)].reset_index(drop=True)\n",
    "# Create testing data: Include only seasons 2324 and 2425\n",
    "testing_data = df.loc[(df['Season'] == 2324) | (df['Season'] == 2425)]\n",
    "\n",
    "X = training_data.drop(['gameId', 'Date', 'Season', 'HomeTeam', 'AwayTeam',  'FTR'], axis=1)\n",
    "Y = training_data['FTR']\n",
    "\n",
    "X_test = testing_data.drop(['gameId', 'Date', 'Season', 'HomeTeam', 'AwayTeam', 'FTR'], axis=1)\n",
    "y_test = testing_data['FTR']\n",
    "\n",
    "print(f\"Training features shape: {X.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")\n",
    "print(f\"Training labels shape: {Y.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd248c0-4729-4e1d-b16d-90711492aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features and Trasform in numeric the Target variable\n",
    "le = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Y = le.fit_transform(Y)      # Away Win = 0 , Draw = 1, # Home Win = 2\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f973cff0-cba9-43ca-8dd0-485e38c81a91",
   "metadata": {},
   "source": [
    "# MachineLearningModels.py - Automated Pipeline for Model Training\r\n",
    "\r\n",
    "The `MachineLearningModels.py` file implements an automated pipeline for training, validation, and optimization of machine learning models with the goal of reducing overfitting, maximizing performance, and comparing key metrics across models. The process also enables the saving of trained models in a dedicated directory (`ML_models`), making them reusable for future applications, such as in the next stage, `Betting_Strategy`.\r\n",
    "\r\n",
    "The models considered include:\r\n",
    "\r\n",
    "- **Logistic Regression (Simple)**: A baseline linear classification model.  \r\n",
    "- **Elastic Net Logistic Regression**: An advanced variant of logistic regression that combines L1 regularization (sparsity) and L2 regularization (shrinkage), particularly useful when dealing with numerous correlated features, as in the given dataset.  \r\n",
    "- **Random Forest**: A tree-based model ideal for exploring complex relationships between variables without requiring significant feature scaling.  \r\n",
    "- **XGBoost (Extreme Gradient Boosting Classifier)**: A highly optimized and powerful gradient-boosting algorithm, designed for complex problems.  \r\n",
    "- **LightGBM (Light Gradient Boosting Machine)**: A lightweight and faster alternative to XGBoost, optimized for handling large datasets.  \r\n",
    "\r\n",
    "The primary goal is to identify the model with the best **F1-weighted score**, a balanced metric particularly suitable for datasets with imbalanced classes.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "# Process Details\r\n",
    "\r\n",
    "The `MachineLearningModels.py` script functions as follows:\r\n",
    "\r\n",
    "1. **Model Initialization**  \r\n",
    "   Each model is initialized with default or pre-defined parameters.\r\n",
    "\r\n",
    "2. **Hyperparameter Optimization**  \r\n",
    "   - **RandomizedSearchCV** is used to perform hyperparameter tuning by testing multiple random combinations of parameters.\r\n",
    "   - For **Random Forest**, **XGBoost**, and **LightGBM**, this optimization is conducted in two phases:\r\n",
    "     - **Broader Search**: An initial exploration of a wide range of parameter values.\r\n",
    "     - **Deeper Search**: A more focused search around the best parameters from the broader search.\r\n",
    "\r\n",
    "3. **Cross-Validation**  \r\n",
    "   - Stratified 5-Fold Cross-Validation (`StratifiedKFold`) is employed to ensure robust evaluation of the models by maintaining the proportion of classes across folds.\r\n",
    "\r\n",
    "4. **Metric Evaluation**  \r\n",
    "   - Each model is evaluated using the **weighted F1-score**. The model with the highest weighted F1-score is selected.\r\n",
    "\r\n",
    "5. **Model Saving**  \r\n",
    "   - Trained models are saved as `.pkl` files in the `ML_models` directory to facilitate reuse without retraining.\r\n",
    "\r\n",
    "6. **Comparison of Models**  \r\n",
    "   - Models are compared based on their weighted F1-scores and other performance metrics (e.g., accuracy, precision, recall). The best model is selected and highlighted.\r\n",
    "\r\n",
    "This systematic approach ensures the selection of an optimal model, balancing computational efficiency and predictive performance.\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f2675-4a81-4fbc-94d4-902145a4cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": train_simple_logistic(X, Y, X_test, y_test),\n",
    "    \"Elastic Net Logistic\": train_elastic_net(X, Y, X_test, y_test),\n",
    "    \"Random Forest\": train_random_forest_improved(X, Y, X_test, y_test),\n",
    "    \"XGBoost\": train_xgboost_improved(X, Y, X_test, y_test),\n",
    "    \"LightGBM\": train_lightgbm_improved(X, Y, X_test, y_test),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b878b4-35d7-41b5-bf45-9e3d7cad1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name, best_model = evaluate_models(models, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b447df-f8a2-478b-827e-700de0561ffe",
   "metadata": {},
   "source": [
    "# Model Performance Analysis\n",
    "\n",
    "## Logistic Regression\n",
    "- **Precision**: High for `away win` (0.62) and `home win` (0.60), but low for `draw` (0.35).\n",
    "- **Recall**: Very high for `home win` (0.82), but extremely low for `draw` (0.11), indicating the model struggles to correctly identify this outcome.\n",
    "- **F1-Score**: Balanced for `away win` and `home win`, but very low for `draw` (0.17).\n",
    "- **Conclusion**: Overall performance is acceptable, but the model struggles with imbalanced outcomes, particularly predicting `draw`.\n",
    "\n",
    "\n",
    "## Elastic Net Logistic Regression\n",
    "- Results are similar to the basic Logistic Regression:\n",
    "  - Slight improvement in **Precision** and **Recall** for `draw` (`precision`: 0.35 → 0.37, `recall`: 0.11 → 0.12).\n",
    "  - No significant improvement for the other outcomes.\n",
    "- **Conclusion**: Adding L1 and L2 regularization provides minor gains but does not significantly outperform the base model.\n",
    "\n",
    "\n",
    "## Random Forest\n",
    "- **Precision**: Improved compared to Logistic Regression, especially for `draw` (0.42), and decent for the other two outcomes.\n",
    "- **Recall**: Balanced overall (`away win`: 0.71, `draw`: 0.26, `home win`: 0.68).\n",
    "- **F1-Score**: Higher across all outcomes compared to Logistic Regression. \n",
    "  - Best performance for `home win` (0.65).\n",
    "- **Conclusion**: Random Forest performs better with imbalanced outcomes due to its ability to handle non-linear relationships and complex features.\n",
    "\n",
    "\n",
    "## XGBoost\n",
    "- **Precision** and **Recall**: Similar to Random Forest, with a slight drop in precision for `away win` and recall for `draw`.\n",
    "- **F1-Score**: Comparable to Random Forest but slightly lower for `draw` (0.29 vs. 0.32).\n",
    "- **Conclusion**: Although powerful, XGBoost does not outperform Random Forest on this dataset, likely due to limited hyperparameter tuning.\n",
    "\n",
    "\n",
    "## LightGBM\n",
    "- **Precision**: Similar to XGBoost, but slightly lower across all outcomes.\n",
    "- **Recall**: Good for `home win` (0.72), but low for `draw` (0.22).\n",
    "- **F1-Score**: Comparable to XGBoost and Random Forest but worse for `draw`.\n",
    "- **Conclusion**: While LightGBM offers excellent training speed, its overall performance is weaker compared to Random Forest.\n",
    "\n",
    "\n",
    "## Confusion Matrix Insights\n",
    "1. **Away Win**: Identified with high precision and recall across all models.\n",
    "2. **Draw**: All models struggle to identify this outcome correctly, with high false negative rates.\n",
    "3. **Home Win**: Consistently well-classified, with high recall across all models.\n",
    "\n",
    "\n",
    "## General Observations\n",
    "1. **Weighted F1-Score**: Random Forest (0.544) emerges as the best model in terms of balancing precision and recall, delivering the highest overall performance.\n",
    "2. **Class Imbalance**: The `draw` outcome poses a significant challenge for all models.\n",
    "3. **Model Selection**: Random Forest offers the best balance between simplicity and performance. While XGBoost and LightGBM may benefit from more aggressive hyperparameter tuning, it's uncertain whether the additional computational resources and time required would significantly enhance their predictive power.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8d3f9-8d0b-49f0-b07f-0663ac85a5f2",
   "metadata": {},
   "source": [
    "\n",
    "--> Proceed to the \"Betting_Strategy\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda76aec-e11b-4395-b45a-d9df4d4fab84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
